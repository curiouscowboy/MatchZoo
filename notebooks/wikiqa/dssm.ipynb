{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/data/users/fyx/.local/python3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/data/users/fyx/.local/python3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matchzoo as mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pack = mz.datasets.wiki_qa.load_data('train', task='ranking')\n",
    "valid_pack = mz.datasets.wiki_qa.load_data('dev', task='ranking', filter=True)\n",
    "predict_pack = mz.datasets.wiki_qa.load_data('test', task='ranking', filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing text_left with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit: 100%|██████████| 2118/2118 [00:00<00:00, 6770.27it/s]\n",
      "Processing text_right with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit: 100%|██████████| 18841/18841 [00:05<00:00, 3242.42it/s]\n",
      "Processing text_left with extend: 100%|██████████| 2118/2118 [00:00<00:00, 523762.51it/s]\n",
      "Processing text_right with extend: 100%|██████████| 18841/18841 [00:00<00:00, 430768.33it/s]\n",
      "Building VocabularyUnit from a datapack.: 100%|██████████| 1614976/1614976 [00:00<00:00, 2863004.74it/s]\n",
      "Processing text_left with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit => WordHashingUnit => SumRepresentUnit: 100%|██████████| 2118/2118 [00:01<00:00, 1412.50it/s]\n",
      "Processing text_right with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit => WordHashingUnit => SumRepresentUnit: 100%|██████████| 18841/18841 [00:44<00:00, 421.13it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = mz.preprocessors.DSSMPreprocessor()\n",
    "train_pack_processed = preprocessor.fit_transform(train_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing text_left with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit => WordHashingUnit => SumRepresentUnit: 100%|██████████| 122/122 [00:00<00:00, 1604.91it/s]\n",
      "Processing text_right with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit => WordHashingUnit => SumRepresentUnit: 100%|██████████| 1115/1115 [00:02<00:00, 438.25it/s]\n",
      "Processing text_left with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit => WordHashingUnit => SumRepresentUnit: 100%|██████████| 237/237 [00:00<00:00, 1638.25it/s]\n",
      "Processing text_right with chain_transform of TokenizeUnit => LowercaseUnit => PuncRemovalUnit => StopRemovalUnit => NgramLetterUnit => WordHashingUnit => SumRepresentUnit: 100%|██████████| 2300/2300 [00:05<00:00, 427.10it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_pack_processed = preprocessor.transform(valid_pack)\n",
    "predict_pack_processed = preprocessor.transform(predict_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_task = mz.tasks.Ranking(loss=mz.losses.RankHingeLoss())\n",
    "ranking_task.metrics = [\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=3),\n",
    "    mz.metrics.NormalizedDiscountedCumulativeGain(k=5),\n",
    "    mz.metrics.MeanAveragePrecision()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter \"name\" set to DSSMModel.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_left (InputLayer)          (None, 9644)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_right (InputLayer)         (None, 9644)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          2893500     text_left[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          2893500     text_right[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          90300       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          90300       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          90300       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          90300       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          38528       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          38528       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 6,225,258\n",
      "Trainable params: 6,225,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = mz.models.DSSMModel()\n",
    "model.params['input_shapes'] = preprocessor.context['input_shapes']\n",
    "model.params['task'] = ranking_task\n",
    "model.params['mlp_num_layers'] = 3\n",
    "model.params['mlp_num_units'] = 300\n",
    "model.params['mlp_num_fan_out'] = 128\n",
    "model.params['mlp_activation_func'] = 'relu'\n",
    "model.guess_and_fill_missing_params()\n",
    "model.build()\n",
    "model.compile()\n",
    "model.backend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x, pred_y = predict_pack_processed[:].unpack()\n",
    "evaluate = mz.callbacks.EvaluateAllMetrics(model, x=pred_x, y=pred_y, batch_size=len(pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = mz.PairDataGenerator(train_pack_processed, num_dup=2, num_neg=1, batch_size=20, shuffle=True)\n",
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "102/102 [==============================] - 8s 75ms/step - loss: 0.9976\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.433040 - normalized_discounted_cumulative_gain@5(0):0.507081 - mean_average_precision(0):0.465983\n",
      "Epoch 2/30\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 0.9881\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.433040 - normalized_discounted_cumulative_gain@5(0):0.507081 - mean_average_precision(0):0.465983\n",
      "Epoch 3/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 0.9729\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.433040 - normalized_discounted_cumulative_gain@5(0):0.505449 - mean_average_precision(0):0.465842\n",
      "Epoch 4/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 0.9661\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.434145 - normalized_discounted_cumulative_gain@5(0):0.505738 - mean_average_precision(0):0.467495\n",
      "Epoch 5/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 0.9212\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.533720 - normalized_discounted_cumulative_gain@5(0):0.614126 - mean_average_precision(0):0.552806\n",
      "Epoch 6/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 0.9175\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.542483 - normalized_discounted_cumulative_gain@5(0):0.604303 - mean_average_precision(0):0.574165\n",
      "Epoch 7/30\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 0.9330\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.433040 - normalized_discounted_cumulative_gain@5(0):0.505449 - mean_average_precision(0):0.465780\n",
      "Epoch 8/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 0.9030\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.591410 - normalized_discounted_cumulative_gain@5(0):0.641630 - mean_average_precision(0):0.589921\n",
      "Epoch 9/30\n",
      "102/102 [==============================] - 7s 68ms/step - loss: 0.9342\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.592967 - normalized_discounted_cumulative_gain@5(0):0.643187 - mean_average_precision(0):0.592030\n",
      "Epoch 10/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 0.9965\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 11/30\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 12/30\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 0.9997\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 13/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 0.9994\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 14/30\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 15/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 16/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 17/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 18/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 19/30\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 20/30\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 21/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 22/30\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 23/30\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 24/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 25/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 26/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 27/30\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 28/30\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 29/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n",
      "Epoch 30/30\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 1.0000\n",
      "Validation: loss:nan - normalized_discounted_cumulative_gain@3(0):0.630590 - normalized_discounted_cumulative_gain@5(0):0.677677 - mean_average_precision(0):0.633078\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=30, callbacks=[evaluate], workers=5, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
